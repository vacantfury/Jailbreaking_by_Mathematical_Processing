# LLM Experiment Framework

A comprehensive framework for running experiments with Large Language Models (LLMs) and evaluating their performance.

## ðŸŒŸ Features

- **Unified Configuration**: Centralized configuration for all components
- **Multiple LLM Support**: Integration with OpenAI GPT and Ollama (Llama) models
- **Extensible Architecture**: Easy to add new models and processors
- **Experiment Management**: Track, save, and compare experiment results
- **Jailbreaking Analysis**: Tools for analyzing jailbreaking attack effectiveness
- **LangChain Integration**: Built on top of the LangChain framework

## ðŸ“‹ Project Structure

```
.
â”œâ”€â”€ config.py                      # Central configuration file
â”œâ”€â”€ setup.py                       # Installation script
â”œâ”€â”€ experiment/                    # Experiment framework
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ experiment_manager.py      # Core experiment management
â”‚   â””â”€â”€ constants.py               # Experiment-specific constants
â”œâ”€â”€ prompt_processing/             # Prompt processing components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ processor.py               # Unified processor interface
â”‚   â”œâ”€â”€ base_processor.py          # Legacy base processor
â”‚   â”œâ”€â”€ LLM_processor.py           # Legacy LLM processor
â”‚   â”œâ”€â”€ gpt_processor.py           # GPT processor implementation
â”‚   â”œâ”€â”€ llama_processor.py         # Llama processor implementation
â”‚   â”œâ”€â”€ non_LLM_processor.py       # Non-LLM processor
â”‚   â””â”€â”€ constants.py               # Prompt-related constants
â”œâ”€â”€ llm_util/                      # LLM utility functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_client.py              # LLM client interface
â”‚   â””â”€â”€ llm_util_example.py        # Example usage
â”œâ”€â”€ jailbreaking_attack_track/     # Jailbreaking attack analysis
â”‚   â”œâ”€â”€ score_calculator.py        # Calculate attack scores
â”‚   â””â”€â”€ analyze_results.py         # Analyze attack results
â””â”€â”€ input_and_output/              # Input and output data
    â”œâ”€â”€ input_prompts.jsonl        # Input prompts
    â”œâ”€â”€ output_prompts.jsonl       # Processed prompts
    â””â”€â”€ experiment_results.jsonl   # Experiment results
```

## ðŸš€ Getting Started

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/llm-experiment-framework.git
cd llm-experiment-framework

# Install the package and dependencies
pip install -e .
```

### Basic Usage

#### 1. Configure your API Keys

For OpenAI:
```
# Set environment variable
export OPENAI_API_KEY=your_key_here

# Or create a key file
echo "your_key_here" > prompt_processing/ChatGPT_key.txt
```

#### 2. Run a Simple Experiment

```python
from experiment.experiment_manager import ExperimentManager

# Create an experiment manager
manager = ExperimentManager("my_experiment")

# Run an experiment with GPT and Llama
result = manager.run_llm_experiment(
    llm_providers=['openai', 'ollama'],
    model_names={
        'openai': 'gpt-3.5-turbo',
        'ollama': 'llama2'
    },
    trials=1
)

print(f"Experiment completed! Results saved to {manager.output_file}")
```

#### 3. Analyze Jailbreaking Results

```bash
python -m jailbreaking_attack_track.analyze_results \
    --input path/to/results.jsonl \
    --output analysis_results.json \
    --verbose
```

## ðŸ“Š Architecture

The framework is built around these core concepts:

1. **LLM Clients**: Wrappers around LLM APIs (OpenAI, Ollama, etc.)
2. **Processors**: Components that take input prompts and produce responses
3. **Experiment Manager**: Coordinates running experiments with multiple processors
4. **Score Calculator**: Analyzes and compares results

## ðŸ”§ Configuration

The `config.py` file contains all the central configuration for the project:

- File paths and default files
- LLM settings (models, parameters)
- System prompts and templates
- Experiment settings
- Jailbreaking attack settings

## ðŸ§© Extending the Framework

### Adding a New LLM Provider

1. Create a new client in `llm_util/llm_client.py`:
```python
class NewProviderClient(BaseLLMClient):
    def _setup(self):
        # Setup code
        
    def query(self, prompt, system_message=None):
        # Implementation
```

2. Add to the factory:
```python
if provider == "new_provider":
    return NewProviderClient(**kwargs)
```

3. Create a processor in `prompt_processing/processor.py`:
```python
class NewProviderProcessor(LLMProcessor):
    def __init__(self, model_name=None, ...):
        super().__init__(
            provider="new_provider",
            model_name=model_name,
            ...
        )
```

## ðŸ“š References

- [LangChain Documentation](https://python.langchain.com/docs/get_started)
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Ollama Documentation](https://ollama.ai/docs) 