{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4151a0b49b1c4cb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:18:31.484198Z",
     "start_time": "2025-02-09T02:18:29.531891Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db071cae48b7359e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading original prompts (\"prompt_develop.jsonl\") and your jailbreak prompts (\"jailbreak_develop.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05f1715d3bfefe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:18:31.492149Z",
     "start_time": "2025-02-09T02:18:31.489545Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'src/input_and_output/input_prompts.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m             prompt_list\u001b[38;5;241m.\u001b[39mappend(json_record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prompt_list\n\u001b[0;32m----> 8\u001b[0m original_prompt_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_prompts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msrc/input_and_output/input_prompts.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# prompt in test phase\u001b[39;00m\n\u001b[1;32m      9\u001b[0m jailbreak_prompt_list \u001b[38;5;241m=\u001b[39m get_prompts(file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc/input_and_output/output_prompts.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mget_prompts\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_prompts\u001b[39m(file_name):\n\u001b[1;32m      2\u001b[0m     prompt_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[1;32m      5\u001b[0m             json_record \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/mambaforge/base/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'src/input_and_output/input_prompts.jsonl'"
     ]
    }
   ],
   "source": [
    "def get_prompts(file_name):\n",
    "    prompt_list = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            json_record = json.loads(line)\n",
    "            prompt_list.append(json_record[\"prompt\"])\n",
    "    return prompt_list\n",
    "original_prompt_list = get_prompts(file_name=\"src/input_and_output/input_prompts.jsonl\") # prompt in test phase\n",
    "jailbreak_prompt_list = get_prompts(file_name=\"src/input_and_output/output_prompts.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5accfaab0fc39d0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading model inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d474f8570988e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:20:45.317742Z",
     "start_time": "2025-02-09T02:18:31.498741Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9643ebdfcdc543ad9f6cc69ef6b08326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "def get_model_inference_pipeline(model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=1024)\n",
    "    return pipe\n",
    "model_id = \"google/gemma-2b-it\" # one test-phase model (we also hold another LLM for test)\n",
    "pipe = get_model_inference_pipeline(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5f15ceccdc103f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loading functions to compute jailbreak scores and stealthiness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea92c08f1a227050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:21:48.634007Z",
     "start_time": "2025-02-09T02:21:40.684710Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_jailbreak_score\n",
    "from utils import get_stl_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f4a048f6b1d88",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Peform model inference with jailbreak prompts and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e72c8bae9618217e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T02:29:38.921023Z",
     "start_time": "2025-02-09T02:21:48.637072Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'original_prompt_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m avg_jailbreak_score, avg_stealthiness_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m, \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m original_prompt, jailbreak_prompt \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mzip\u001b[39m(\u001b[43moriginal_prompt_list\u001b[49m, jailbreak_prompt_list)):\n\u001b[1;32m      5\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: jailbreak_prompt},\n\u001b[1;32m      7\u001b[0m     ]\n\u001b[1;32m      8\u001b[0m     response \u001b[38;5;241m=\u001b[39m pipe(messages)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'original_prompt_list' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "avg_jailbreak_score, avg_stealthiness_score = 0., 0.\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "for original_prompt, jailbreak_prompt in tqdm(zip(original_prompt_list, jailbreak_prompt_list)):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": jailbreak_prompt},\n",
    "    ]\n",
    "    response = pipe(messages)[0]['generated_text'][1]['content']\n",
    "    jailbreak_score = get_jailbreak_score(pipe, original_prompt, jailbreak_prompt, response, tokenizer) # In the test phase, the evaluation model and evaluation prompts are held out to avoid adaptive attack on the judge model. This is just an example of model judge. We will consistently use Gemma-2b-it tokenizer to detect jailbreak prompt with length over 100.\n",
    "    stl_score = get_stl_score(original_prompt, jailbreak_prompt)\n",
    "    record = {\"original_prompt\": original_prompt, \"jailbreak_prompt\": jailbreak_prompt, \"response\": response, \"jailbreak_score\": jailbreak_score, \"stealthiness_score\": stl_score}\n",
    "    results.append(record)\n",
    "    avg_jailbreak_score += jailbreak_score / len(jailbreak_prompt_list)\n",
    "    avg_stealthiness_score += stl_score / len(jailbreak_prompt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cb7112879469a5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Store and show final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17224dda01e45d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T06:11:29.277459100Z",
     "start_time": "2025-01-31T06:11:29.273460800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_name = \"src/input_and_output/test_results.jsonl\"\n",
    "with open(file_name, 'w') as file:\n",
    "    for dictionary in results:\n",
    "        json_record = json.dumps(dictionary)\n",
    "        file.write(json_record + \"\\n\")\n",
    "print(f'Average jailbreak score: {avg_jailbreak_score}') # 0.151 for PAP jailbreak\n",
    "print(f'Average stealthiness score: {avg_stealthiness_score}') # 0.220 for PAP jailbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7fc298ed81ef5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
